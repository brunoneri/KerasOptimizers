{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimizer colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunoneri/KerasOptimizers/blob/master/optimizer_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y83v7fOyWOR5",
        "colab_type": "code",
        "outputId": "8163117b-6b49-48ec-e169-29caa8c7be82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (41.6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEP78-O7WtxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow â‰¥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH7wn61e4Ao6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_diagnostic(history, opt_label):\n",
        "  train_label='{} train'.format(opt_label)\n",
        "  val_label= '{} val'.format(opt_label)\n",
        "  #plot loss  \n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.title('Cross Entropy Loss') \n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss') \n",
        "  plt.plot(history.history['loss'], color='pink', label= train_label)\n",
        "  plt.plot(history.history['val_loss'], color='gray', label=val_label)\n",
        "  plt.legend([train_label,val_label], loc='upper right')\n",
        "  # plot accuracy\n",
        "  plt.show()\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.title('Classification Accuracy')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.plot(history_rmsprop.history['accuracy'], color='pink', label=train_label)\n",
        "  plt.plot(history_rmsprop.history['val_accuracy'], color='gray', label=val_label)\n",
        "  plt.legend([train_label,val_label], loc='lower right')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os3dJzkcXzG0",
        "colab_type": "text"
      },
      "source": [
        "Let's train a neural network on Fashion MNIST using the Leaky ReLU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yKKLPZjVhL_",
        "colab_type": "code",
        "outputId": "a2e7235c-7205-4bb0-baac-de20b45d3a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "x_train= x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ShU787gZZg0",
        "colab_type": "code",
        "outputId": "ffe4a282-5f39-4ab0-db17-c783e3b6fd0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#  breaking  the training data into train / validation sets\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        "\n",
        "# Reshape input data from (28, 28) to (28, 28, 1)\n",
        "w, h = 28, 28\n",
        "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
        "\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "\n",
        "print(x_train.shape[0], 'train set')\n",
        "print(x_valid.shape[0], 'validation set')\n",
        "print(x_test.shape[0], 'test set')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
            "55000 train set\n",
            "5000 validation set\n",
            "10000 test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNNzFUymYKH9",
        "colab_type": "code",
        "outputId": "c167c38e-a646-4aa3-a361-b12aeffde6b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 412,778\n",
            "Trainable params: 412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMkKNuNIZd4P",
        "colab_type": "text"
      },
      "source": [
        "SGD optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPuxaMPPYTe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=0.001),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKsxpNksYcUu",
        "colab_type": "code",
        "outputId": "95f98f6e-b1c7-4702-88c9-b8ee3f4fc6e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "history_sgd = model.fit(x_train, y_train, epochs=10,batch_size=64,\n",
        "                    validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 85s 2ms/sample - loss: 2.2660 - accuracy: 0.1528 - val_loss: 2.2002 - val_accuracy: 0.3628\n",
            "Epoch 2/10\n",
            "55000/55000 [==============================] - 83s 2ms/sample - loss: 2.0501 - accuracy: 0.2872 - val_loss: 1.7805 - val_accuracy: 0.5460\n",
            "Epoch 3/10\n",
            "55000/55000 [==============================] - 83s 2ms/sample - loss: 1.6004 - accuracy: 0.4140 - val_loss: 1.2416 - val_accuracy: 0.6064\n",
            "Epoch 4/10\n",
            "55000/55000 [==============================] - 83s 2ms/sample - loss: 1.3230 - accuracy: 0.4853 - val_loss: 1.0459 - val_accuracy: 0.6238\n",
            "Epoch 5/10\n",
            "55000/55000 [==============================] - 83s 2ms/sample - loss: 1.1873 - accuracy: 0.5333 - val_loss: 0.9594 - val_accuracy: 0.6342\n",
            "Epoch 6/10\n",
            "55000/55000 [==============================] - 83s 2ms/sample - loss: 1.1098 - accuracy: 0.5602 - val_loss: 0.9073 - val_accuracy: 0.6528\n",
            "Epoch 7/10\n",
            "55000/55000 [==============================] - 83s 2ms/sample - loss: 1.0559 - accuracy: 0.5781 - val_loss: 0.8708 - val_accuracy: 0.6694\n",
            "Epoch 8/10\n",
            "50112/55000 [==========================>...] - ETA: 7s - loss: 1.0133 - accuracy: 0.5984"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K63zqv5MZjiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_diagnostic(history_sgd,\"sgd\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3HWeoyUZss3",
        "colab_type": "text"
      },
      "source": [
        "SGD with momentum optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c26FbPVhoPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN234C0JaHKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_momentum = model.fit(x_train, y_train, epochs=10,batch_size=64,\n",
        "                    validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDB8R_OPaAqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_diagnostic(history_momentum,\"Momentum\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPx9UINma38b",
        "colab_type": "text"
      },
      "source": [
        "Nesterov optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XFFphLKFaGLb",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or6K57FCbKZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_momentum_nesterov = model.fit(x_train, y_train, epochs=10,batch_size=64,\n",
        "                    validation_data=(x_valid, y_valid))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81LeUM6saV73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_diagnostic(history_momentum_nesterov,\"Nesterov\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sdUrj1ub47S",
        "colab_type": "text"
      },
      "source": [
        "RMSProp optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXnUc8_Lb9Mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.9),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtVAEk-Ob_03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_rmsprop = model.fit(x_train, y_train, epochs=10,batch_size=64,\n",
        "                    validation_data=(x_valid, y_valid))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44WnPVxZaoTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_diagnostic(history_rmsprop,\"RMSProp\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QeR5OYndNdZ",
        "colab_type": "text"
      },
      "source": [
        "Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWw8f9krdMMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SxjKI0hdSd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
        "\n",
        "history_adam = model.fit(x_train, y_train, epochs=10,batch_size=64,\n",
        "                    validation_data=(x_valid, y_valid), callbacks=[checkpointer])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQthLDQszlRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_diagnostic(history_adam,\"Adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inRCwr3_a4lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Plot of the learning curves"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWuYuSnMf9zB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot learning curves\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(history_sgd.history['loss'], color='blue', label='SGD train')\n",
        "plt.plot(history_sgd.history['val_loss'], color='orange', label='SGD val')\n",
        "plt.plot(history_momentum.history['loss'], color='green', label='Momentum train')\n",
        "plt.plot(history_momentum.history['val_loss'], color='red', label='Momentum val')\n",
        "plt.plot(history_momentum_nesterov.history['loss'], color='purple', label='Nesterov train')\n",
        "plt.plot(history_momentum_nesterov.history['val_loss'], color='brown', label='Nesterov val')\n",
        "plt.plot(history_rmsprop.history['loss'], color='pink', label='RMSProp train')\n",
        "plt.plot(history_rmsprop.history['val_loss'], color='gray', label='RMSProp val')\n",
        "plt.plot(history_adam.history['loss'], color='olive', label='Adam train')\n",
        "plt.plot(history_adam.history['val_loss'], color='cyan', label='Adam val')\n",
        "plt.legend(['SGD train', 'SGD val','Momentum train','Momentum val','Nesterov train', 'Nesterov val','RMSProp train','RMSProp val','Adam train', 'Adam val'], loc='upper right')\n",
        "# plot accuracy\n",
        "plt.show()\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title('Classification Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.plot(history_sgd.history['accuracy'], color='blue', label='SGD train')\n",
        "plt.plot(history_sgd.history['val_accuracy'], color='orange', label='SGD val')\n",
        "plt.plot(history_momentum.history['accuracy'], color='green', label='Momentum train')\n",
        "plt.plot(history_momentum.history['val_accuracy'], color='red', label='Momentum val')\n",
        "plt.plot(history_momentum_nesterov.history['accuracy'], color='purple', label='Nesterov train')\n",
        "plt.plot(history_momentum_nesterov.history['val_accuracy'], color='brown', label='Nesterov val')\n",
        "plt.plot(history_rmsprop.history['accuracy'], color='pink', label='RMSProp train')\n",
        "plt.plot(history_rmsprop.history['val_accuracy'], color='gray', label='RMSProp val')\n",
        "plt.plot(history_adam.history['accuracy'], color='olive', label='Adam train')\n",
        "plt.plot(history_adam.history['val_accuracy'], color='cyan', label='Adam val')\n",
        "plt.legend(['SGD train', 'SGD val','Momentum train','Momentum val','Nesterov train', 'Nesterov val','RMSProp train','RMSProp val','Adam train', 'Adam val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6QYjjMcP0bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f-iFoFtNq--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr9j8iOFgMZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset text labels\n",
        "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
        "                        \"Trouser\",      # index 1\n",
        "                        \"Pullover\",     # index 2 \n",
        "                        \"Dress\",        # index 3 \n",
        "                        \"Coat\",         # index 4\n",
        "                        \"Sandal\",       # index 5\n",
        "                        \"Shirt\",        # index 6 \n",
        "                        \"Sneaker\",      # index 7 \n",
        "                        \"Bag\",          # index 8 \n",
        "                        \"Ankle boot\"]   # index 9\n",
        "\n",
        "\n",
        "y_hat = model.predict(x_test)\n",
        "\n",
        "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
        "figure = plt.figure(figsize=(20, 8))\n",
        "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
        "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
        "    # Display each image\n",
        "    ax.imshow(np.squeeze(x_test[index]))\n",
        "    predict_index = np.argmax(y_hat[index])\n",
        "    true_index = np.argmax(y_test[index])\n",
        "    # Set the title for each image\n",
        "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
        "                                  fashion_mnist_labels[true_index]),\n",
        "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}